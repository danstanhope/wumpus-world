{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fl0gJZgb0aa0"
   },
   "outputs": [],
   "source": [
    "class North:\n",
    "    def turnLeft(self):\n",
    "        return West\n",
    "\n",
    "    def turnRight(self):\n",
    "        return East\n",
    "\n",
    "class South:\n",
    "    def turnLeft(self):\n",
    "        return East\n",
    "\n",
    "    def turnRight(self):\n",
    "        return West\n",
    "\n",
    "class East:\n",
    "    def turnLeft(self):\n",
    "        return North\n",
    "\n",
    "    def turnRight(self):\n",
    "        return South\n",
    "\n",
    "class West:\n",
    "    def turnLeft(self):\n",
    "        return South\n",
    "\n",
    "    def turnRight(self):\n",
    "        return North"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u-g25Lkm0BDs"
   },
   "outputs": [],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from enum import Enum\n",
    "\n",
    "class Action(Enum):\n",
    "    Forward = \"Forward\"\n",
    "    TurnLeft = \"TurnLeft\"\n",
    "    TurnRight = \"TurnRight\"\n",
    "    Shoot = \"Shoot\"\n",
    "    Grab = \"Grab\"\n",
    "    Climb = \"Climb\"\n",
    "\n",
    "\n",
    "class Coords:\n",
    "    def __init__(self, x, y):\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "\n",
    "    def adjacentCells(self, gridWidth, gridHeight):\n",
    "        toLeft = Coords(self._x - 1, self._y ) if (self._x > 0) else False\n",
    "        toRight =  Coords(self._x + 1, self._y ) if (self._x < gridWidth - 1) else False\n",
    "        below = Coords(self._x, self._y  - 1) if (self._y  > 0) else False\n",
    "        above = Coords(self._x, self._y  + 1) if (self._y  < gridHeight - 1) else False\n",
    "\n",
    "        return [toLeft, toRight, below, above]\n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._x\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "\n",
    "\n",
    "class Percept:\n",
    "    def __init__(self, stench, breeze, glitter, bump, scream, isTerminated, reward):\n",
    "        self.stench = stench\n",
    "        self.breeze = breeze\n",
    "        self.glitter = glitter\n",
    "        self.bump = bump\n",
    "        self.scream = scream\n",
    "        self.isTerminated = isTerminated\n",
    "        self.reward = reward\n",
    "\n",
    "    def show(self):\n",
    "        return \"stench:%s breeze:%s glitter:%s bump:%s scream:%s isTerminated:%s reward:%s\" % (self.stench, self.breeze, self.glitter, self.bump, self.scream, self.isTerminated, self.reward)\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self,\n",
    "                 gridWidth,\n",
    "                 gridHeight,\n",
    "                 pitProb,\n",
    "                 allowClimbWithoutGold,\n",
    "                 agent,\n",
    "                 pitLocations,\n",
    "                 isTerminated,\n",
    "                 wumpusLocation,\n",
    "                 wumpusAlive,\n",
    "                 goldLocation):\n",
    "        self.gridWidth = gridWidth\n",
    "        self.gridHeight = gridHeight\n",
    "        self.pitProb = pitProb\n",
    "        self.allowClimbWithoutGold = allowClimbWithoutGold\n",
    "        self.agent = agent\n",
    "        self.pitLocations = pitLocations\n",
    "        self.isTerminated = isTerminated\n",
    "        self.wumpusLocation = wumpusLocation\n",
    "        self.wumpusAlive = wumpusAlive\n",
    "        self.goldLocation = goldLocation\n",
    "\n",
    "    def isPitAt(self, coords):\n",
    "        for item in self.pitLocations:\n",
    "            if(item.x == coords.x and item.y == coords.y):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def isWumpusAt(self, coords):\n",
    "        if(self.wumpusLocation is None):\n",
    "            return False\n",
    "        elif(self.wumpusLocation.x == coords.x and self.wumpusLocation.y == coords.y):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def isAgentAt(self, coords):\n",
    "        if(self.agent.location.x == coords.x and self.agent.location.y == coords.y):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def isGlitter(self):\n",
    "        if(self.goldLocation is None):\n",
    "            return False\n",
    "        elif(self.agent.location.x == self.goldLocation.x and self.agent.location.y == self.goldLocation.y):\n",
    "            return True\n",
    "        else:\n",
    "            return False           \n",
    "\n",
    "    def isGoldAt(self, coords):\n",
    "        if(self.goldLocation is None):\n",
    "            return False\n",
    "        elif(coords.x == self.goldLocation.x and coords.y == self.goldLocation.y):\n",
    "            return True\n",
    "        else:\n",
    "            return False         \n",
    "\n",
    "    def killAttemptSuccessful(self):\n",
    "        if(self.wumpusLocation is None):\n",
    "            return True\n",
    "\n",
    "        wumpusInLineOfFire = False\n",
    "        \n",
    "        if self.agent.orientation == West:\n",
    "            if (self.agent.location.x > self.wumpusLocation.x and self.agent.location.y == self.wumpusLocation.y):\n",
    "                wumpusInLineOfFire = True\n",
    "        elif self.agent.orientation == East:\n",
    "            if (self.agent.location.x < self.wumpusLocation.x and self.agent.location.y == self.wumpusLocation.y):\n",
    "                wumpusInLineOfFire = True\n",
    "        elif self.agent.orientation == South:\n",
    "            if (self.agent.location.x == self.wumpusLocation.x and self.agent.location.y > self.wumpusLocation.y):\n",
    "                wumpusInLineOfFire = True\n",
    "        elif self.agent.orientation == North:\n",
    "            if (self.agent.location.x == self.wumpusLocation.x and self.agent.location.y < self.wumpusLocation.y):\n",
    "                wumpusInLineOfFire = True\n",
    "        \n",
    "        return self.agent.hasArrow and self.wumpusAlive and wumpusInLineOfFire\n",
    "\n",
    "    def adjacentCells(self, coords):\n",
    "        toLeft = Coords(coords.x - 1, coords.y) if (coords.x > 0) else False\n",
    "        toRight =  Coords(coords.x + 1, coords.y) if (coords.x < self.gridWidth - 1) else False\n",
    "        below = Coords(coords.x, coords.y - 1) if (coords.y > 0) else False\n",
    "        above = Coords(coords.x, coords.y + 1) if (coords.y < self.gridHeight - 1) else False\n",
    "\n",
    "        return [toLeft, toRight, below, above]\n",
    "\n",
    "    def isPitAdjacent(self, coords):\n",
    "        adjacent = self.adjacentCells(coords)\n",
    "        for item in adjacent:\n",
    "            if(item != False):\n",
    "                if(self.isPitAt(item)):\n",
    "                    return True\n",
    "                    \n",
    "        return False\n",
    "\n",
    "    def isWumpusAdjacent(self, coords):\n",
    "        adjacent = self.adjacentCells(coords)\n",
    "\n",
    "        for item in adjacent:\n",
    "            if(item != False):\n",
    "                if(self.isWumpusAt(item)):\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def isBreeze(self):\n",
    "        return self.isPitAdjacent(self.agent.location)\n",
    "\n",
    "    def isStench(self):\n",
    "        return self.isWumpusAdjacent(self.agent.location) or self.isWumpusAt(self.agent.location)\n",
    "\n",
    "    def applyAction(self, action):\n",
    "        if (self.isTerminated):\n",
    "            return self, Percept(False, False, False, False, False, True, 0)\n",
    "        else:\n",
    "            if action.name is Action.Forward.name:                \n",
    "                movedAgent = self.agent.forward(\n",
    "                    self.gridWidth, self.gridHeight)\n",
    "\n",
    "                death = (self.isWumpusAt(movedAgent.location)\n",
    "                         and self.wumpusAlive) or self.isPitAt(movedAgent.location)\n",
    "                \n",
    "                newAgent = deepcopy(movedAgent)\n",
    "                newAgent.isAlive = False if death else True\n",
    "\n",
    "                Bump = False\n",
    "                if(newAgent.location.x == self.agent.location.x and newAgent.location.y == self.agent.location.y):\n",
    "                    Bump = True\n",
    "                \n",
    "                newEnv = Environment(self.gridWidth, self.gridHeight, self.pitProb, self.allowClimbWithoutGold, newAgent, self.pitLocations,\n",
    "                                     death, self.wumpusLocation, self.wumpusAlive, newAgent.location if self.agent.hasGold else self.goldLocation)\n",
    "                return newEnv, Percept(newEnv.isStench(), newEnv.isBreeze(), newEnv.isGlitter(), Bump, False, False if newAgent.isAlive else True,  -1 if newAgent.isAlive else -1001)\n",
    "            elif action.name is Action.TurnLeft.name:\n",
    "                return Environment(self.gridWidth, self.gridHeight, self.pitProb, self.allowClimbWithoutGold, self.agent.turnLeft(), self.pitLocations, self.isTerminated,  self.wumpusLocation,  self.wumpusAlive,  self.goldLocation), Percept(self.isStench(), self.isBreeze(), self.isGlitter(), False, False,  False, -1)\n",
    "            elif action.name is Action.TurnRight.name:\n",
    "                return Environment(self.gridWidth, self.gridHeight, self.pitProb, self.allowClimbWithoutGold, self.agent.turnRight(), self.pitLocations, self.isTerminated, self.wumpusLocation, self.wumpusAlive, self.goldLocation), Percept(self.isStench(), self.isBreeze(), self.isGlitter(), False, False,  False, -1)\n",
    "            elif action.name is Action.Grab.name:\n",
    "                newAgent = deepcopy(self.agent)\n",
    "                newAgent.hasGold = self.isGlitter()\n",
    "\n",
    "                return Environment(self.gridWidth, self.gridHeight, self.pitProb, self.allowClimbWithoutGold, newAgent, self. pitLocations, self.isTerminated, self.wumpusLocation, self.wumpusAlive, self.agent.location if newAgent.hasGold else self.goldLocation), Percept(self.isStench(), self.isBreeze(), self.isGlitter(), False, False,  False, -1)\n",
    "            elif action.name is Action.Climb.name:\n",
    "                inStartLocation = False\n",
    "                if(self.agent.location.x == Coords(0, 0).x and self.agent.location.y == Coords(0, 0).y):\n",
    "                    inStartLocation = True\n",
    "\n",
    "                success = self.agent.hasGold and inStartLocation\n",
    "                isTerminated = success or self.allowClimbWithoutGold\n",
    "\n",
    "                return Environment(self.gridWidth, self.gridHeight, self.pitProb, self.allowClimbWithoutGold, self.agent, self.pitLocations, isTerminated, self.wumpusLocation, self.wumpusAlive, self.goldLocation), Percept(False, False, self.agent.hasGold, False, False, isTerminated, 999 if success else -1)\n",
    "            elif action.name is Action.Shoot.name:\n",
    "                hadArrow = self.agent.hasArrow\n",
    "                wumpusKilled = self.killAttemptSuccessful()\n",
    "                newAgent = deepcopy(self.agent)\n",
    "                newAgent.hasArrow = False\n",
    "                return Environment(self.gridWidth, self.gridHeight, self.pitProb, self.allowClimbWithoutGold, newAgent, self.pitLocations, self.isTerminated, self.wumpusLocation, self.wumpusAlive and not wumpusKilled, self.goldLocation), Percept(self.isStench(), self.isBreeze(), self.isGlitter(), False, wumpusKilled, False, -11 if hadArrow else -1)\n",
    "\n",
    "    def visualize(self):\n",
    "        wumpusSymbol =  \"W\" if (self.wumpusAlive == True) else \"w\"         \n",
    "\n",
    "        Rows = []\n",
    "        for y in range(self.gridHeight):\n",
    "            Cells = []\n",
    "            for x in range(self.gridWidth):\n",
    "                A = \"A\" if (self.isAgentAt(Coords(x, y))) else \" \"\n",
    "                P = \"P\" if (self.isPitAt(Coords(x, y))) else \" \"\n",
    "                G = \"G\" if (self.isGoldAt(Coords(x, y))) else \" \"\n",
    "                W = wumpusSymbol if (self.isWumpusAt(Coords(x, y))) else \" \"\n",
    "                \n",
    "                Cells.append(\"%s%s%s%s\" % (A, P, G, W))\n",
    "\n",
    "            Rows.append('|'.join(Cells))\n",
    "\n",
    "        return '\\n'.join(Rows)\n",
    "\n",
    "class WumpusWorldEnvironment:\n",
    "    def apply(self, gridWidth, gridHeight, pitProb, allowClimbWithoutGold):\n",
    "        self.gridWidth = gridWidth\n",
    "        self.gridHeight = gridHeight\n",
    "        self.pitProb = pitProb\n",
    "        self.allowClimbWithoutGold = allowClimbWithoutGold\n",
    "\n",
    "        cellIndexes = []\n",
    "        pitLocations = []\n",
    "\n",
    "        for x in range(gridWidth):\n",
    "            for y in range(gridHeight):\n",
    "                cellIndexes.append(Coords(x, y))\n",
    "\n",
    "        cellIndexes.pop(0)\n",
    "        pitCount = 0\n",
    "        for item in cellIndexes:\n",
    "            if random.uniform(0, 1) < pitProb:\n",
    "                if(pitCount == 3):\n",
    "                    break\n",
    "                pitLocations.append(item)\n",
    "                pitCount = pitCount + 1\n",
    "\n",
    "        env = Environment(\n",
    "            gridWidth,\n",
    "            gridHeight,\n",
    "            pitProb,\n",
    "            allowClimbWithoutGold,\n",
    "            Agent(),\n",
    "            pitLocations,\n",
    "            False,\n",
    "            self.randomLocationExceptOrigin(),\n",
    "            True,\n",
    "            self.randomLocationExceptOrigin()\n",
    "        )\n",
    "\n",
    "        return env, Percept(env.isStench(), env.isBreeze(), False, False, False, False,  0.0)\n",
    "\n",
    "    def randomLocationExceptOrigin(self):\n",
    "        x = random.randrange(self.gridWidth)\n",
    "        y = random.randrange(self.gridHeight)\n",
    "\n",
    "        if x == 0 and y == 0:\n",
    "            self.randomLocationExceptOrigin()\n",
    "        else:\n",
    "            return Coords(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AqrL7w4E0fYA"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, location = Coords(0,0), orientation = East, hasGold = False, hasArrow = True, isAlive = True):\n",
    "        self.location =  location\n",
    "        self.orientation = orientation\n",
    "        self.hasGold = hasGold\n",
    "        self.hasArrow = hasArrow\n",
    "        self.isAlive = isAlive\n",
    "\n",
    "    def turnLeft(self):\n",
    "        ret = deepcopy(self)\n",
    "        ret.orientation = self.orientation.turnLeft(self)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def turnRight(self):\n",
    "        ret = deepcopy(self)\n",
    "        ret.orientation  = self.orientation.turnRight(self)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def useArrow(self):\n",
    "        ret = deepcopy(self)\n",
    "        ret.hasArrow = False\n",
    "    \n",
    "        return ret\n",
    "\n",
    "    def forward(self, gridWidth, gridHeight):\n",
    "        ret = deepcopy(self)\n",
    "        \n",
    "        newAgentLocation = False\n",
    "\n",
    "        if self.orientation == West:\n",
    "            newAgentLocation = Coords(max(0, self.location.x - 1), self.location.y)\n",
    "        elif self.orientation == East:\n",
    "            newAgentLocation = Coords(min(gridWidth - 1, self.location.x + 1), self.location.y)\n",
    "        elif self.orientation == South:\n",
    "            newAgentLocation = Coords(self.location.x, max(0, self.location.y - 1))\n",
    "        elif self.orientation == North:\n",
    "            newAgentLocation = Coords(self.location.x, min(gridHeight - 1, self.location.y + 1))\n",
    "\n",
    "\n",
    "        ret.location = newAgentLocation\n",
    "        \n",
    "        return ret\n",
    "\n",
    "    def applyMoveAction(self, action, gridWidth, gridHeight):\n",
    "        if action == Action.Forward:\n",
    "            return self.forward(gridWidth, gridHeight)\n",
    "        elif action == Action.TurnRight:\n",
    "            return self.turnRight()\n",
    "        elif action == Action.TurnLeft:\n",
    "            return self.turnLeft()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4DxIXwnq0tIT"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from random import randrange\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\".\")\n",
    "\n",
    "\n",
    "class DeepQAgent():\n",
    "    def __init__(self, gridHeight=4, gridWidth=4, agentState=Agent, safeLocations=[Coords(0,0)], stenchLocations=[], breezeLocations=[], agentLocationGrid = [], safeLocationGrid = [], stenchLocationGrid = [], breezeLocationGrid = [], agentHasGold = False, agentSensesGold = False, agentHasArrow = False, agentHeardScream = False, agentOrientationSet= False, previousAction = [], previousLocation = [], sameMovesSet = [], sameLocationSet = []):\n",
    "        self.gridHeight = gridHeight\n",
    "        self.gridWidth = gridWidth\n",
    "        self.agentState = agentState()\n",
    "        self.safeLocations = safeLocations\n",
    "        self.stenchLocations = stenchLocations\n",
    "        self.breezeLocations = breezeLocations\n",
    "        self.agentLocationGrid = agentLocationGrid\n",
    "        self.safeLocationGrid = safeLocationGrid\n",
    "        self.stenchLocationGrid = stenchLocationGrid\n",
    "        self.breezeLocationGrid = breezeLocationGrid\n",
    "        self.agentHasGold = agentHasGold\n",
    "        self.agentSensesGold = agentSensesGold\n",
    "        self.agentHasArrow = agentHasArrow\n",
    "        self.agentHeardScream = agentHeardScream\n",
    "        self.agentOrientationSet = agentOrientationSet\n",
    "        self.previousAction = previousAction\n",
    "        self.previousLocation = previousLocation\n",
    "        self.sameMovesSet = sameMovesSet\n",
    "        self.sameLocationSet = sameLocationSet\n",
    "\n",
    "    #Helper method to print grids nicely\n",
    "    def printTable(self, grid):\n",
    "        rows = []\n",
    "        for i in range(self.gridHeight):\n",
    "            cells = []\n",
    "            for j in range(self.gridWidth):            \n",
    "                cells.append(\"%s\" % (grid[i][j]))\n",
    "\n",
    "            rows.append('|'.join(cells))\n",
    "        return '\\n'.join(rows)\n",
    "\n",
    "    #Helper method to print all the different belief state values\n",
    "    def printBeliefState(self, percept):\n",
    "        print(\"-- Percept --\")\n",
    "        print(percept.show())\n",
    "\n",
    "        print('-- Current Agent Location --')\n",
    "        print(self.printTable(self.agentLocationGrid))\n",
    "\n",
    "        print('-- Agent Orientation Set --')\n",
    "        print(self.agentOrientationSet)        \n",
    "\n",
    "        print('-- Safe Locations --')\n",
    "        print(self.printTable(self.safeLocationGrid))\n",
    "\n",
    "        print('-- Stench Locations --')\n",
    "        print(self.printTable(self.stenchLocationGrid))\n",
    "\n",
    "        print('-- Breeze Locations --')\n",
    "        print(self.printTable(self.breezeLocationGrid))    \n",
    "\n",
    "        print('-- Agent Has Gold --')\n",
    "        print(self.agentHasGold)  \n",
    "\n",
    "        print('-- Agent Senses Gold --')\n",
    "        print(self.agentSensesGold)  \n",
    "\n",
    "        print('-- Agent Has Arrow --')\n",
    "        print(self.agentHasArrow)  \n",
    "\n",
    "        print('-- Agent Heard Scream --')\n",
    "        print(self.agentHeardScream)          \n",
    "\n",
    "    #flattening and concatenating all the arrays to one array of length 78\n",
    "    def getAgentBeliefState(self):          \n",
    "        return np.concatenate((np.array(self.agentLocationGrid).flatten(), np.array(self.safeLocationGrid).flatten(),np.array(self.stenchLocationGrid).flatten(), np.array(self.breezeLocationGrid).flatten(), np.array(self.agentOrientationSet).flatten(), np.array(self.agentHasGold).flatten(), np.array(self.agentSensesGold).flatten(), np.array(self.agentHasArrow).flatten(), np.array(self.agentHeardScream).flatten()))\n",
    "\n",
    "    #Set is represented as a list of 1s and 0s\n",
    "    #I don't think the order matters, but we'll say:\n",
    "    #  [1, 0, 0, 0] = North\n",
    "    #  [0, 1, 0, 0] = South\n",
    "    #  [0, 0, 1, 0] = East\n",
    "    #  [0, 0, 0, 1] = West\n",
    "    def buildAgentOrientatioSet(self, orientation):\n",
    "        orientationSet = []\n",
    "\n",
    "        if orientation == North:\n",
    "            orientationSet.append([1, 0, 0, 0])\n",
    "        elif orientation == South:\n",
    "            orientationSet.append([0, 1, 0, 0])\n",
    "        elif orientation == East:\n",
    "            orientationSet.append([0, 0, 1, 0])\n",
    "        elif orientation == West:\n",
    "            orientationSet.append([0, 0, 0, 1])\n",
    "\n",
    "        return orientationSet\n",
    "\n",
    "    #Build counters for last number of moves and if they are the same\n",
    "    def buildSameMoves(self, moves):\n",
    "        sequence = 1\n",
    "        reversed_moves = moves[::-1]\n",
    "        fiveSame = 0         \n",
    "        tenSame = 0         \n",
    "        fiftySame = 0         \n",
    "        for index, move in enumerate(reversed_moves):\n",
    "            if index + 1 == len(reversed_moves):\n",
    "                break\n",
    "          \n",
    "            if(move == reversed_moves[index + 1]):\n",
    "                sequence += 1\n",
    "            else:\n",
    "                break\n",
    "        if sequence >= 5:\n",
    "            fiveSame = 1\n",
    "\n",
    "        if sequence >= 10:\n",
    "            tenSame = 1\n",
    "\n",
    "        if sequence >= 50:\n",
    "            fiftySame = 1  \n",
    "\n",
    "        return [fiveSame, tenSame, fiftySame] \n",
    "\n",
    "    #Build counters for last number of locations and if they are the same\n",
    "    def buildSameLocations(self, locations):\n",
    "        sequence = 1\n",
    "        reversed_locations = locations[::-1]\n",
    "        fourSame = 0         \n",
    "        tenSame = 0         \n",
    "        fiftySame = 0         \n",
    "        for index, location in enumerate(reversed_locations):\n",
    "            if index + 1 == len(reversed_locations):\n",
    "                break\n",
    "          \n",
    "            if(location.x == reversed_locations[index + 1].x and location.y == reversed_locations[index + 1].y):\n",
    "                sequence += 1\n",
    "            else:\n",
    "                break\n",
    "        if sequence >= 4:\n",
    "            fourSame = 1\n",
    "\n",
    "        if sequence >= 10:\n",
    "            tenSame = 1\n",
    "\n",
    "        if sequence >= 50:\n",
    "            fiftySame = 1  \n",
    "\n",
    "        return [fourSame, tenSame, fiftySame]                      \n",
    "\n",
    "    #Build agent location grid\n",
    "    def buildAgentLocationGrid(self, coords):\n",
    "        rows = []\n",
    "\n",
    "        for i in range(self.gridHeight):\n",
    "            cols = []\n",
    "            for j in range(self.gridWidth):\n",
    "                if(i == coords.y and j == coords.x):\n",
    "                    cols.append(1)\n",
    "                else:\n",
    "                    cols.append(0)   \n",
    "\n",
    "            rows.append(cols)\n",
    "\n",
    "        return rows\n",
    "    \n",
    "    #Build safe location grid\n",
    "    def buildSafeLocationGrid(self, visited):\n",
    "        rows = []\n",
    "\n",
    "        for i in range(self.gridHeight):\n",
    "            cols = []\n",
    "            for j in range(self.gridWidth):\n",
    "                if any(d.y == i and d.x == j for d in visited):\n",
    "                    cols.append(1)\n",
    "                else:\n",
    "                    cols.append(0)   \n",
    "\n",
    "            rows.append(cols)\n",
    "\n",
    "        return rows            \n",
    "\n",
    "    #Build stench location grid\n",
    "    def buildStenchLocationGrid(self, stenches):\n",
    "        rows = []\n",
    "\n",
    "        for i in range(self.gridHeight):\n",
    "            cols = []\n",
    "            for j in range(self.gridWidth):\n",
    "                if any(d.y == i and d.x == j for d in stenches):\n",
    "                    cols.append(1)\n",
    "                else:\n",
    "                    cols.append(0)   \n",
    "\n",
    "            rows.append(cols)\n",
    "\n",
    "        return rows \n",
    "    \n",
    "    #Build breeze location grid\n",
    "    def buildBreezeLocationGrid(self, breezes):\n",
    "        rows = []\n",
    "\n",
    "        for i in range(self.gridHeight):\n",
    "            cols = []\n",
    "            for j in range(self.gridWidth):\n",
    "                if any(d.y == i and d.x == j for d in breezes):\n",
    "                    cols.append(1)\n",
    "                else:\n",
    "                    cols.append(0)   \n",
    "\n",
    "            rows.append(cols)\n",
    "\n",
    "        return rows\n",
    "\n",
    "    #apply next action. Action value is passed in from training(0,1,2,4,5)\n",
    "    def nextAction(self, percept, action):\n",
    "        ret = deepcopy(self)\n",
    "        \n",
    "        ret.previousAction.append(action)\n",
    "        ret.previousLocation.append(ret.agentState.location)\n",
    "        \n",
    "        if(percept.stench == True):\n",
    "            ret.stenchLocations.append(ret.agentState.location)\n",
    "        if(percept.breeze == True):\n",
    "            ret.breezeLocations.append(ret.agentState.location) \n",
    "\n",
    "        ret.agentLocationGrid = self.buildAgentLocationGrid(ret.agentState.location)\n",
    "        ret.safeLocationGrid = self.buildSafeLocationGrid(ret.safeLocations)  \n",
    "        ret.stenchLocationGrid = self.buildStenchLocationGrid(ret.stenchLocations)       \n",
    "        ret.breezeLocationGrid = self.buildBreezeLocationGrid(ret.breezeLocations)\n",
    "        ret.agentHasGold =  1 if ret.agentState.hasGold == True else 0\n",
    "        ret.agentSensesGold = 1 if percept.glitter == True else 0\n",
    "        ret.agentHasArrow = 1 if ret.agentState.hasArrow == True else 0\n",
    "        ret.agentHeardScream = 1 if percept.scream == True else 0\n",
    "        ret.agentOrientationSet = self.buildAgentOrientatioSet(ret.agentState.orientation)\n",
    "\n",
    "        if action == 0:\n",
    "            ret.agentState = ret.agentState.forward(\n",
    "                self.gridWidth, self.gridHeight)\n",
    "            ret.safeLocations.append(ret.agentState.location)\n",
    "\n",
    "            return ret, Action.Forward\n",
    "        elif action == 1:\n",
    "            ret.agentState = ret.agentState.turnLeft()\n",
    "            return ret, Action.TurnLeft\n",
    "        elif action == 2:\n",
    "            ret.agentState = ret.agentState.turnRight()\n",
    "            return ret, Action.TurnRight\n",
    "        elif action == 3:\n",
    "            ret.agentState = ret.agentState.useArrow()\n",
    "            return ret, Action.Shoot\n",
    "        if action == 4:\n",
    "            if percept.glitter == True:\n",
    "                ret.agentState.hasGold = True\n",
    "\n",
    "            return ret, Action.Grab\n",
    "        if action == 5:\n",
    "            ret.agentState.isTerminated = True\n",
    "            return ret, Action.Climb                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from matplotlib import pylab as plt\n",
    "from collections import deque\n",
    "from random import randrange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(path):\n",
    "    model = torch.load(path)\n",
    "    return model\n",
    "\n",
    "def run(env, agent, percept, action):\n",
    "    agent, action = agent.nextAction(percept, action)\n",
    "    env, percept = env.applyAction(action)\n",
    "\n",
    "    return env, agent, percept\n",
    "\n",
    "def getState(belief_state):\n",
    "    state_ = np.array([belief_state]).reshape(1,l1) + np.random.rand(1,l1)/100.0   \n",
    "    state = torch.from_numpy(state_).float()\n",
    "\n",
    "    return state_, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = 72\n",
    "epsilon = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStateTest(belief_state):\n",
    "    state_ = np.array([belief_state]).reshape(1,l1) + np.random.rand(1,l1)/10.0   \n",
    "    state = torch.from_numpy(state_).float()\n",
    "\n",
    "    return state_, state\n",
    "\n",
    "\n",
    "def test_model_alternate(model, mode='static', display=True):\n",
    "    i = 0\n",
    "    terminated = False\n",
    "    world = WumpusWorldEnvironment()\n",
    "    initialEnv, initialPercept = world.apply(4, 4, 0.2, False)        \n",
    "    agent = DeepQAgent(4, 4)    \n",
    "    randGen = randrange(6)\n",
    "    env, agent, percept = run(initialEnv, agent, initialPercept, randGen)\n",
    "    belief_state = agent.getAgentBeliefState()\n",
    "    state_, state = getStateTest(belief_state)\n",
    "\n",
    "    status = 1\n",
    "    reward = 0\n",
    "    mov = 0\n",
    "    won_counter = 0\n",
    "    \n",
    "    while terminated == False:\n",
    "        qval = model(state)\n",
    "        qval_ = qval.data.numpy()\n",
    "        action_ = np.argmax(qval_)\n",
    "        nextMove = action_.item()\n",
    "        if (random.random() < epsilon):\n",
    "            nextMove = np.random.randint(0,6)\n",
    "        else:\n",
    "            action_ = np.argmax(qval_)\n",
    "            nextMove = action_.item()\n",
    "#             nextMove = np.argmax(qval_)\n",
    "        env, agent, percept = run(env, agent, percept, nextMove) \n",
    "\n",
    "        belief_state = agent.getAgentBeliefState()\n",
    "        state_, state = getState(belief_state)       \n",
    "        reward += percept.reward\n",
    "        \n",
    "        if reward > 0:\n",
    "            won_counter += 1\n",
    "            terminated = True\n",
    "\n",
    "        if mov > 500:\n",
    "            terminated = True\n",
    "\n",
    "        if percept.isTerminated == True:\n",
    "            terminated = True\n",
    "\n",
    "        mov += 1  \n",
    "\n",
    "        # print(percept.show())\n",
    "        # print(reward, status)\n",
    "        clear_output(wait=True)\n",
    "        print(env.visualize())\n",
    "        print(\"-----------------------\")\n",
    "    win = True if won_counter > 0 else False\n",
    "    return win, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Test winRate: 3.0%, averageScorePerGame: -977.08"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 1: trial_1 3000 epochs, train winrate 2% \n",
    "l1 = 72\n",
    "l2 = 150\n",
    "l3 = 100\n",
    "l4 = 6 \n",
    "gamma=0.9\n",
    "epsilon=0.3\n",
    "epochs=3000\n",
    "max_moves=500\n",
    "mem_size=1000\n",
    "batch_size=200\n",
    "learning_rate = 1e-3\n",
    "sync_freq = 500\n",
    "\n",
    "## 2: Trial_2: Train winrate: 5%, test winrate: 0% \n",
    "\n",
    "epochs=1000\n",
    "batch_size:128\n",
    "\n",
    "## Train winrate: 5%\n",
    "\n",
    "\n",
    "##3: Trial_3: 2000 epoch, train win_rate: 3.35%, test win_rate: 2.6%\n",
    "epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karanteckwani/Projects/wumpus-world/wumpusWorld/model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'model')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print(model_path)\n",
    "model_filename = 'deepQ_wumpus_model.pt'\n",
    "model_file_path = os.path.join(model_path, model_filename)\n",
    "model = get_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |    |    |   W\n",
      "AP  |    |    |    \n",
      "    |    | P  |    \n",
      " P  |    |    |  G \n",
      "-----------------------\n",
      "99 3\n",
      "Games played: 100, # of wins: 3\n",
      "Win percentage: 3.0%\n",
      "average_reward: -977.08\n"
     ]
    }
   ],
   "source": [
    "max_games = 100\n",
    "wins = 0\n",
    "total_reward = []\n",
    "\n",
    "for i in range(max_games):\n",
    "    win, reward = test_model_alternate(model, mode='random', display=False)\n",
    "    total_reward.append(reward)\n",
    "    if win:\n",
    "        wins += 1\n",
    "    print(i, wins)\n",
    "win_perc = float(wins) / float(max_games)\n",
    "print(\"Games played: {0}, # of wins: {1}\".format(max_games,wins))\n",
    "print(\"Win percentage: {}%\".format(100.0*win_perc))\n",
    "print(f\"average_reward: {sum(total_reward)/len(total_reward)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Test winRate: 1.0%, averageScorePerGame: -987.43"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4: Trial_5: train:2.51%, test:4.1%\n",
    "l1 = 72\n",
    "l2 = 512\n",
    "l3 = 128\n",
    "l4 = 6 \n",
    "gamma=0.85\n",
    "epsilon=0.3\n",
    "epochs=10000\n",
    "max_moves=250\n",
    "mem_size=1000\n",
    "batch_size=200\n",
    "learning_rate = 1e-3\n",
    "sync_freq = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karanteckwani/Projects/wumpus-world/wumpusWorld/model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'model')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print(model_path)\n",
    "model_filename = 'deepQ_wumpus_model_2.pt'\n",
    "model_file_path = os.path.join(model_path, model_filename)\n",
    "model = get_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |AP  | P  |    \n",
      "    |    |    |    \n",
      "    |    |    |    \n",
      "  G |    |    |   W\n",
      "-----------------------\n",
      "99 1\n",
      "Games played: 100, # of wins: 1\n",
      "Win percentage: 1.0%\n",
      "average_reward: -987.43\n"
     ]
    }
   ],
   "source": [
    "max_games = 100\n",
    "wins = 0\n",
    "total_reward = []\n",
    "\n",
    "for i in range(max_games):\n",
    "    win, reward = test_model_alternate(model, mode='random', display=False)\n",
    "    total_reward.append(reward)\n",
    "    if win:\n",
    "        wins += 1\n",
    "    print(i, wins)\n",
    "win_perc = float(wins) / float(max_games)\n",
    "print(\"Games played: {0}, # of wins: {1}\".format(max_games,wins))\n",
    "print(\"Win percentage: {}%\".format(100.0*win_perc))\n",
    "print(f\"average_reward: {sum(total_reward)/len(total_reward)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Test winRate: 4.0%, averageScorePerGame: -954.44"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4: Trial_6: gamma 0.85, l2:512, l3:128, l4: 128, train:2.53%, test:3.0% \n",
    "l1 = 72\n",
    "l2 = 512\n",
    "l3 = 128\n",
    "l4 = 128\n",
    "l5 = 6\n",
    "gamma=0.85\n",
    "epsilon=0.3\n",
    "epochs=10000\n",
    "max_moves=250\n",
    "mem_size=1000\n",
    "batch_size=200\n",
    "learning_rate = 1e-3\n",
    "sync_freq = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karanteckwani/Projects/wumpus-world/wumpusWorld/model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'model')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print(model_path)\n",
    "model_filename = 'deepQ_wumpus_model_5layers.pt'\n",
    "model_file_path = os.path.join(model_path, model_filename)\n",
    "model = get_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |AP  |    |    \n",
      "    | P  |  G |    \n",
      "    |    |    |    \n",
      "    |   W|    |    \n",
      "-----------------------\n",
      "99 4\n",
      "Games played: 100, # of wins: 4\n",
      "Win percentage: 4.0%\n",
      "average_reward: -954.44\n"
     ]
    }
   ],
   "source": [
    "max_games = 100\n",
    "wins = 0\n",
    "total_reward = []\n",
    "\n",
    "for i in range(max_games):\n",
    "    win, reward = test_model_alternate(model, mode='random', display=False)\n",
    "    total_reward.append(reward)\n",
    "    if win:\n",
    "        wins += 1\n",
    "    print(i, wins)\n",
    "win_perc = float(wins) / float(max_games)\n",
    "print(\"Games played: {0}, # of wins: {1}\".format(max_games,wins))\n",
    "print(\"Win percentage: {}%\".format(100.0*win_perc))\n",
    "print(f\"average_reward: {sum(total_reward)/len(total_reward)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unwinnable Games Quit Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WumpusWorldEnvironment:\n",
    "    def apply(self, gridWidth, gridHeight, pitProb, allowClimbWithoutGold):\n",
    "        self.gridWidth = gridWidth\n",
    "        self.gridHeight = gridHeight\n",
    "        self.pitProb = pitProb\n",
    "        self.allowClimbWithoutGold = allowClimbWithoutGold\n",
    "\n",
    "        cellIndexes = []\n",
    "        pitLocations = []\n",
    "\n",
    "        for x in range(gridWidth):\n",
    "            for y in range(gridHeight):\n",
    "                cellIndexes.append(Coords(x, y))\n",
    "\n",
    "        cellIndexes.pop(0)\n",
    "        pitCount = 0\n",
    "        \n",
    "        pitLocations.append(Coords(1, 0))\n",
    "        pitLocations.append(Coords(0, 1))\n",
    "\n",
    "        env = Environment(\n",
    "            gridWidth,\n",
    "            gridHeight,\n",
    "            pitProb,\n",
    "            allowClimbWithoutGold,\n",
    "            Agent(),\n",
    "            pitLocations,\n",
    "            False,\n",
    "            self.randomLocationExceptOrigin(),\n",
    "            True,\n",
    "            self.randomLocationExceptOrigin()\n",
    "        )\n",
    "\n",
    "        return env, Percept(env.isStench(), env.isBreeze(), False, False, False, False,  0.0)\n",
    "\n",
    "    def randomLocationExceptOrigin(self):\n",
    "        x = random.randrange(self.gridWidth)\n",
    "        y = random.randrange(self.gridHeight)\n",
    "\n",
    "        if x == 0 and y == 0:\n",
    "            self.randomLocationExceptOrigin()\n",
    "        else:\n",
    "            return Coords(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStateTest(belief_state):\n",
    "    state_ = np.array([belief_state]).reshape(1,l1) + np.random.rand(1,l1)/10.0   \n",
    "    state = torch.from_numpy(state_).float()\n",
    "\n",
    "    return state_, state\n",
    "\n",
    "\n",
    "def test_model_alternate(model, mode='static', display=True):\n",
    "    i = 0\n",
    "    terminated = False\n",
    "    world = WumpusWorldEnvironment()\n",
    "    initialEnv, initialPercept = world.apply(4, 4, 0.2, False)        \n",
    "    agent = DeepQAgent(4, 4)    \n",
    "    randGen = randrange(6)\n",
    "    env, agent, percept = run(initialEnv, agent, initialPercept, randGen)\n",
    "    belief_state = agent.getAgentBeliefState()\n",
    "    state_, state = getStateTest(belief_state)\n",
    "\n",
    "    status = 1\n",
    "    reward = 0\n",
    "    mov = 0\n",
    "    won_counter = 0\n",
    "    agent_safe_escape_counter = 0\n",
    "\n",
    "    while terminated == False:\n",
    "        qval = model(state)\n",
    "        qval_ = qval.data.numpy()\n",
    "\n",
    "        if (random.random() < epsilon):\n",
    "            nextMove = np.random.randint(0,6)\n",
    "        else:\n",
    "            action_ = np.argmax(qval_)\n",
    "            nextMove = action_.item()\n",
    "\n",
    "        env, agent, percept = run(env, agent, percept, nextMove) \n",
    "\n",
    "        belief_state = agent.getAgentBeliefState()\n",
    "        state_, state = getState(belief_state)       \n",
    "        reward += percept.reward        \n",
    "        \n",
    "                \n",
    "        if nextMove == 5:\n",
    "            agent_safe_escape_counter += 1\n",
    "            terminated = True\n",
    "\n",
    "        if reward > 0:\n",
    "            won_counter += 1\n",
    "            terminated = True\n",
    "\n",
    "        if mov > 500:\n",
    "            terminated = True\n",
    "\n",
    "        if percept.isTerminated == True:\n",
    "            terminated = True\n",
    "\n",
    "        mov += 1  \n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(env.visualize())\n",
    "        print(\"-----------------------\")\n",
    "    win = True if won_counter > 0 else False\n",
    "    agent_safe_escape = True if agent_safe_escape_counter > 0 else False\n",
    "    \n",
    "    return win, agent_safe_escape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Test quitRate: 63%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 1: trial_1 3000 epochs, train winrate 2% \n",
    "l1 = 72\n",
    "l2 = 150\n",
    "l3 = 100\n",
    "l4 = 6 \n",
    "gamma=0.9\n",
    "epsilon=0.3\n",
    "epochs=3000\n",
    "max_moves=500\n",
    "mem_size=1000\n",
    "batch_size=200\n",
    "learning_rate = 1e-3\n",
    "sync_freq = 500\n",
    "\n",
    "## 2: Trial_2: Train winrate: 5%, test winrate: 0% \n",
    "\n",
    "epochs=1000\n",
    "batch_size:128\n",
    "\n",
    "## Train winrate: 5%\n",
    "\n",
    "\n",
    "##3: Trial_3: 2000 epoch, train win_rate: 3.35%, test win_rate: 2.6%\n",
    "epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karanteckwani/Projects/wumpus-world/wumpusWorld/model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'model')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print(model_path)\n",
    "model_filename = 'deepQ_wumpus_model.pt'\n",
    "model_file_path = os.path.join(model_path, model_filename)\n",
    "model = get_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |AP  |    |    \n",
      " P  |    |    |    \n",
      "   W|  G |    |    \n",
      "    |    |    |    \n",
      "-----------------------\n",
      "Games played: 100, # of safe escapes: 63\n",
      "Safe Escape percentage: 63.0%\n"
     ]
    }
   ],
   "source": [
    "max_games = 100\n",
    "wins = 0\n",
    "agent_safe_escapes = 0\n",
    "\n",
    "for i in range(max_games):\n",
    "    win, agent_safe_escape = test_model_alternate(model, mode='random', display=False)\n",
    "    if win:\n",
    "        wins += 1\n",
    "    if agent_safe_escape:\n",
    "        agent_safe_escapes += 1  \n",
    "\n",
    "safe_escape_perc = float(agent_safe_escapes) / float(max_games)\n",
    "print(\"Games played: {0}, # of safe escapes: {1}\".format(max_games,agent_safe_escapes))\n",
    "print(\"Safe Escape percentage: {}%\".format(100.0*safe_escape_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Test quitRate: 71%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4: Trial_5: train:2.51%, test:4.1%\n",
    "l1 = 72\n",
    "l2 = 512\n",
    "l3 = 128\n",
    "l4 = 6 \n",
    "gamma=0.85\n",
    "epsilon=0.3\n",
    "epochs=10000\n",
    "max_moves=250\n",
    "mem_size=1000\n",
    "batch_size=200\n",
    "learning_rate = 1e-3\n",
    "sync_freq = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karanteckwani/Projects/wumpus-world/wumpusWorld/model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'model')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print(model_path)\n",
    "model_filename = 'deepQ_wumpus_model_2.pt'\n",
    "model_file_path = os.path.join(model_path, model_filename)\n",
    "model = get_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |APG |    |    \n",
      " P  |    |    |    \n",
      "    |    |    |    \n",
      "   W|    |    |    \n",
      "-----------------------\n",
      "Games played: 100, # of safe escapes: 71\n",
      "Safe Escape percentage: 71.0%\n"
     ]
    }
   ],
   "source": [
    "max_games = 100\n",
    "wins = 0\n",
    "agent_safe_escapes = 0\n",
    "\n",
    "for i in range(max_games):\n",
    "    win, agent_safe_escape = test_model_alternate(model, mode='random', display=False)\n",
    "    if win:\n",
    "        wins += 1\n",
    "    if agent_safe_escape:\n",
    "        agent_safe_escapes += 1  \n",
    "\n",
    "safe_escape_perc = float(agent_safe_escapes) / float(max_games)\n",
    "print(\"Games played: {0}, # of safe escapes: {1}\".format(max_games,agent_safe_escapes))\n",
    "print(\"Safe Escape percentage: {}%\".format(100.0*safe_escape_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Test quitRate: 48%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4: Trial_6: gamma 0.85, l2:512, l3:128, l4: 128, train:2.53%, test:3.0% \n",
    "l1 = 72\n",
    "l2 = 512\n",
    "l3 = 128\n",
    "l4 = 128\n",
    "l5 = 6\n",
    "gamma=0.85\n",
    "epsilon=0.3\n",
    "epochs=10000\n",
    "max_moves=250\n",
    "mem_size=1000\n",
    "batch_size=200\n",
    "learning_rate = 1e-3\n",
    "sync_freq = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karanteckwani/Projects/wumpus-world/wumpusWorld/model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'model')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print(model_path)\n",
    "model_filename = 'deepQ_wumpus_model_5layers.pt'\n",
    "model_file_path = os.path.join(model_path, model_filename)\n",
    "model = get_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |AP W|    |    \n",
      " P  |  G |    |    \n",
      "    |    |    |    \n",
      "    |    |    |    \n",
      "-----------------------\n",
      "Games played: 100, # of safe escapes: 48\n",
      "Safe Escape percentage: 48.0%\n"
     ]
    }
   ],
   "source": [
    "max_games = 100\n",
    "wins = 0\n",
    "agent_safe_escapes = 0\n",
    "\n",
    "for i in range(max_games):\n",
    "    win, agent_safe_escape = test_model_alternate(model, mode='random', display=False)\n",
    "    if win:\n",
    "        wins += 1\n",
    "    if agent_safe_escape:\n",
    "        agent_safe_escapes += 1  \n",
    "\n",
    "safe_escape_perc = float(agent_safe_escapes) / float(max_games)\n",
    "print(\"Games played: {0}, # of safe escapes: {1}\".format(max_games,agent_safe_escapes))\n",
    "print(\"Safe Escape percentage: {}%\".format(100.0*safe_escape_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward = []"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wumpus-world.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
